{
	"name": "data_lake_load_dotnet",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "demo2",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"language_info": {
				"name": "csharp"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/b99affbe-2256-409d-a682-c20a3963070b/resourceGroups/sandbox-2-rg/providers/Microsoft.Synapse/workspaces/synapsesandboxdv/bigDataPools/demo2",
				"name": "demo2",
				"type": "Spark",
				"endpoint": "https://synapsesandboxdv.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/demo2",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 10,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"source": [
					"## Batch load to Data Lake using C# Spark\n",
					"\n",
					"A good reference for additional syntax examples: https://github.com/dotnet/spark/blob/master/examples/Microsoft.Spark.CSharp.Examples/Sql/Batch/Basic.cs\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"// from pyspark.sql.functions import col, desc, regexp_replace, substring, to_date, from_json, explode, expr\n",
					"// from pyspark.sql.types import StructType, StringType\n",
					"using Microsoft.Spark.Sql;\n",
					"using Microsoft.Spark.Sql.Types;\n",
					"using static Microsoft.Spark.Sql.Functions;\n",
					"\n",
					"\n",
					"var taxi_zone_path = \"abfss://demo@dvtrainingadls.dfs.core.windows.net/nyctaxi/lookups/taxi_zone\";\n",
					"var taxi_rate_path = \"abfss://demo@dvtrainingadls.dfs.core.windows.net/nyctaxi/lookups/taxi_rate_code\";\n",
					"var yellow_delta_path = \"abfss://demo@dvtrainingadls.dfs.core.windows.net/nyctaxi/tripdata/yellow_delta\";\n",
					"\n",
					"var date_format = \"yyyy-MM-dd HH:mm:ss\";\n",
					"\n",
					"// Define a schema that Spark understands. This is one of several ways to do it.\n",
					"var trip_schema = new StructType(new[]\n",
					"{\n",
					"    new StructField(\"VendorID\", new IntegerType()),\n",
					"    new StructField(\"tpep_pickup_datetime\", new StringType()),\n",
					"    new StructField(\"tpep_dropoff_datetime\", new StringType()),\n",
					"    new StructField(\"passenger_count\", new IntegerType()),\n",
					"    new StructField(\"trip_distance\", new DoubleType()),\n",
					"    new StructField(\"RatecodeID\", new IntegerType()),\n",
					"    new StructField(\"store_and_fwd_flag\", new StringType()),\n",
					"    new StructField(\"PULocationID\", new IntegerType()),\n",
					"    new StructField(\"DOLocationID\", new IntegerType()),\n",
					"    new StructField(\"payment_type\", new IntegerType()),\n",
					"    new StructField(\"fare_amount\", new DoubleType()),\n",
					"    new StructField(\"extra\", new DoubleType()),\n",
					"    new StructField(\"mta_tax\", new DoubleType()),\n",
					"    new StructField(\"tip_amount\", new DoubleType()),\n",
					"    new StructField(\"tolls_amount\", new DoubleType()),\n",
					"    new StructField(\"improvement_surcharge\", new DoubleType()),\n",
					"    new StructField(\"total_amount\", new DoubleType())\n",
					"});"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"var input_df = spark.Read()\n",
					"    .Option(\"header\",\"true\")\n",
					"    .Option(\"inferSchema\", \"true\")\n",
					"    .Csv(\"abfss://demo@dvtrainingadls.dfs.core.windows.net/nyctaxi/lookups/taxi_zone_lookup.csv\"); \n",
					"\n",
					"\n",
					"var df = input_df.WithColumnRenamed(\"service_zone\", \"ServiceZone\");\n",
					"\n",
					"df.Write().Format(\"delta\").Mode(\"overwrite\").Save(taxi_zone_path);"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					"%%pyspark\n",
					"df = (\n",
					"    spark.option(\"header\",\"true\")\n",
					"    .option(\"inferSchema\", \"true\")\n",
					"    .csv(\"abfss://demo@dvtrainingadls.dfs.core.windows.net/nyctaxi/lookups/taxi_zone_lookup.csv\")\n",
					")\n",
					"df.show()"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"// If you want to delete the trips table before starting, keep following line uncommented\n",
					"// dbutils.fs.rm(yellow_delta_path,recurse=True)\n",
					"spark.Conf().Set(\"spark.sql.shuffle.partitions\", \"18\");\n",
					"\n",
					"var input_df = spark.Read()\n",
					"    .Option(\"header\",\"true\")\n",
					"    .Schema(trip_schema)\n",
					"    .Csv(\"abfss://demo@dvtrainingadls.dfs.core.windows.net/nyctaxi/tripdata/yellow/2019/yellow_tripdata_2019-*\");\n",
					"// .Option(\"inferSchema\", \"true\")\n",
					"\n",
					"// Take your pick on how to transform, withColumn or SQL Expressions. Only one of these is needed.\n",
					"// Option A\n",
					"var transformed_df = input_df\n",
					"    .WithColumn(\"year_month\", RegexpReplace(Substring(Col(\"tpep_pickup_datetime\"),1,7), \"-\", \"_\"))\n",
					"    .WithColumn(\"pickup_dt\", ToDate(Col(\"tpep_pickup_datetime\"), date_format)) \n",
					"    .WithColumn(\"dropoff_dt\", ToDate(Col(\"tpep_dropoff_datetime\"), date_format))\n",
					"    .WithColumn(\"tip_pct\", Col(\"tip_amount\") / Col(\"total_amount\"));\n",
					"  \n",
					"// Option B\n",
					"// var transformed_df = input_df.SelectExpr(\n",
					"//                   \"*\",\n",
					"//                   \"replace(left(tpep_pickup_datetime, 7),\\\"-\\\",\\\"_\\\") as year_month\",\n",
					"//                   $\"to_date(tpep_pickup_datetime, \\\"{date_format}\\\") as pickup_dt\",\n",
					"//                   $\"to_date(tpep_dropoff_datetime, \\\"{date_format}\\\") as dropoff_dt\",\n",
					"//                   $\"tip_amount/total_amount as tip_pct\");\n",
					"\n",
					"var zone_df = spark.Read().Format(\"delta\").Load(taxi_zone_path);\n",
					"\n",
					"// Join to bring in Taxi Zone data\n",
					"var trip_df = transformed_df\n",
					"     .Join(zone_df, transformed_df[\"PULocationID\"] == zone_df[\"LocationID\"], \"left\").Drop(\"LocationID\")\n",
					"     .WithColumnRenamed(\"Burough\", \"PickupBurrough\")\n",
					"     .WithColumnRenamed(\"Zone\", \"PickupZone\")\n",
					"     .WithColumnRenamed(\"ServiceZone\", \"PickupServiceZone\");\n",
					"\n",
					"trip_df.Write().Mode(\"overwrite\").PartitionBy(\"year_month\").Format(\"delta\").Save(yellow_delta_path);\n",
					""
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"source": [
					"## Test read\n",
					"Simple test read of the delta formatted data that was just saved.\n",
					""
				]
			},
			{
				"cell_type": "code",
				"source": [
					"var test_df = spark.Read().Format(\"delta\").Load(yellow_delta_path).Limit(20);\n",
					"test_df.Select(\"VendorID\", \"tpep_pickup_datetime\", \"tpep_dropoff_datetime\", \"passenger_count\").Show();"
				],
				"execution_count": null
			}
		]
	}
}