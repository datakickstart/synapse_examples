{
  "metadata": {
    "saveOutput": true,
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [],
      "metadata": {},
      "source": [
        "from pyspark.sql.functions import col, desc, regexp_replace, substring, to_date, from_json, explode, expr\n",
        "from pyspark.sql.types import StructType, StringType\n",
        "\n",
        "yellow_source_path = \"wasbs://nyctlc@azureopendatastorage.blob.core.windows.net/yellow/puYear=2018/puMonth=*/*.parquet\"\n",
        "taxi_zone_source_path = \"abfss://demo@datakickstartadls.dfs.core.windows.net/nyctaxi/lookups/taxi_zone_lookup.csv\"\n",
        "\n",
        "taxi_zone_path = \"abfss://demo@datakickstartadls.dfs.core.windows.net/nyctaxi/lookups/taxi_zone\"\n",
        "taxi_rate_path = \"abfss://demo@datakickstartadls.dfs.core.windows.net/nyctaxi/lookups/taxi_rate_code\"\n",
        "yellow_delta_path = \"abfss://demo@datakickstartadls.dfs.core.windows.net/nyctaxi/tripdata/yellow_delta\"\n",
        "\n",
        "date_format = \"yyyy-MM-dd HH:mm:ss\"\n",
        "\n",
        "# Define a schema that Spark understands. This is one of several ways to do it.\n",
        "taxi_zone_schema = (\n",
        "  StructType()\n",
        "    .add('LocationID', 'integer')\n",
        "    .add('Borough', 'string')\n",
        "    .add('Zone', 'string')\n",
        "    .add('ServiceZone', 'string')\n",
        ")"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "metadata": {},
      "source": [
        "zone_df = (\n",
        "  spark.read\n",
        "    .option(\"header\",\"true\")\n",
        "    .schema(taxi_zone_schema)\n",
        "    .csv(taxi_zone_source_path) \n",
        "  )\n",
        "\n",
        "zone_df.write.format(\"delta\").mode(\"overwrite\").save(taxi_zone_path)"
      ],
      "attachments": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [],
      "metadata": {},
      "source": [
        "input_df = spark.read.parquet(yellow_source_path)\n",
        "\n",
        "# Take your pick on how to transform, withColumn or SQL Expressions. Only one of these is needed.\n",
        "# Option A\n",
        "# transformed_df = (\n",
        "#   input_df\n",
        "#     .withColumn(\"yearMonth\", regexp_replace(substring(\"tpepPickupDatetime\",1,7), '-', '_'))\n",
        "#     .withColumn(\"pickupDt\", to_date(\"tpepPickupDatetime\", date_format)) \n",
        "#     .withColumn(\"dropoffDt\", to_date(\"tpepDropoffDatetime\", date_format))\n",
        "#     .withColumn(\"tipPct\", col(\"tipAmount\") / col(\"totalAmount\"))\n",
        "# )\n",
        "  \n",
        "# Option B\n",
        "transformed_df = input_df.selectExpr(\n",
        "                  \"*\",\n",
        "                  \"replace(left(tpepPickupDatetime, 7),'-','_') as yearMonth\",\n",
        "                  f\"to_date(tpepPickupDatetime, '{date_format}') as pickupDt\",\n",
        "                  f\"to_date(tpepDropoffDatetime, '{date_format}') as dropoffDt\",\n",
        "                  f\"tipAmount/totalAmount as tipPct\")\n",
        "\n",
        "zone_df = spark.read.format(\"delta\").load(taxi_zone_path)\n",
        "\n",
        "# Join to bring in Taxi Zone data\n",
        "trip_df = (\n",
        "   transformed_df\n",
        "     .join(zone_df, transformed_df[\"PULocationID\"] == zone_df[\"LocationID\"], how=\"left\").drop(\"LocationID\")\n",
        "     .withColumnRenamed(\"Burough\", \"PickupBurrough\")\n",
        "     .withColumnRenamed(\"Zone\", \"PickupZone\")\n",
        "     .withColumnRenamed(\"ServiceZone\", \"PickupServiceZone\")\n",
        ")\n",
        "\n",
        "trip_df.write.mode(\"overwrite\").partitionBy(\"yearMonth\").format(\"delta\").save(yellow_delta_path)\n",
        ""
      ],
      "attachments": {}
    }
  ]
}